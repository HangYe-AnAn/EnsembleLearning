% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bagging_lasso_model.R
\name{bagging_lasso_model}
\alias{bagging_lasso_model}
\title{Bagging Lasso Model}
\usage{
bagging_lasso_model(X, y, n_bags = 100, K = NULL)
}
\arguments{
\item{X}{A data frame or matrix containing the predictor variables.}

\item{y}{A vector containing the response variable (Binary or continuous).}

\item{n_bags}{Number of bootstrap samples to create (default is 100).}

\item{K}{A positive integer specifying the number of top informative predictors to select; must be greater than the number of predictors. (Optional)}
}
\value{
bagging_lasso_model returns an object of class "list". A list with:
\item{predictions}{The averaged coefficient estimates of the final fitted model.}
\item{variable_importance}{Importance of each predictor variable calculated by counting the number of times each variable appears in the non-missing coefficients across all bootstrap samples.}
}
\description{
The bagging_Lasso_model function takes predictor variables (X) and a response variable (y) as inputs, along with optional parameters for the number of bags (n_bags), the number of top predictors to consider (K). It then fits multiple Lasso regression models using bootstrap sampling and aggregates their predictions to improve model accuracy.
}
\details{
The function generates n_bags bootstrap samples from the original dataset.
\cr
\cr
\enumerate{For each bootstrap sample:
\item It fits a Lasso regression model (using \code{\link[glmnet]{glmnet}}) using cross-validation to find the optimal regularization parameter, or minimum lambda. It then extracts the coefficients of the fitted Lasso models.
\item If the K is specified, and if p >> n, it will pre-screen for top K most “informative” predictors (For more information see \code{\link[simpleEnsembleGroup7]{returnTopK}}). Then it fits a Lasso regression model(using \code{\link[glmnet]{glmnet}}) using the top K predictors and using cross-validation to find the optimal regularization parameter, or minimum lambda. It then extracts the coefficients of the fitted Lasso models.
}
\cr
\cr
Coefficient Aggregation: The coefficients from all bootstrap samples are combined and aggregated by taking the average, or row means, across all bootstrap samples with equal weights. This provides the final coefficient estimates of the final Lasso model.
\cr
\cr
Variable Importance: The function calculates the importance of each predictor variable by counting the number of times each variable appears in the non-missing coefficients across all bootstrap samples.
\cr
\cr
Output: The function returns a list containing the average coefficient estimates (predictions) and the variable importance scores (variable_importance).
\cr
\cr
 \eqn{\alpha=1} corresponds to the Lasso penalty.
}
\examples{
# Load required libraries
library(glmnet)
# Generate sample data
n <- 100  # Number of observations
n_predictors <- 10  # Number of predictors
# Create predictor variables
predictors <- matrix(rnorm(n * n_predictors), ncol = n_predictors)

# Create names for the predictors
predictor_names <- c("Predictor1", "Predictor2", "Predictor3", "Predictor4", "Predictor5", "Predictor6", "Predictor7", "Predictor8", "Predictor9", "Predictor10")
# Assign names to the columns of the predictors matrix
colnames(predictors) <- predictor_names

# Generate response variable
response <- rnorm(n)

# Run bagging lasso regression
result <- bagging_lasso_model(predictors, response, K = 5)
# Print the average coefficient estimate
print(result$predictions)
# Print variable importance
print(result$variable_importance)
}
