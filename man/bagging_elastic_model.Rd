% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bagging_elastic_model.R
\name{bagging_elastic_model}
\alias{bagging_elastic_model}
\title{Bagging Elastic Net Model}
\usage{
bagging_elastic_model(X, y, alpha = 0.5, n_bags = 100, K = NULL)
}
\arguments{
\item{X}{A data frame or matrix containing the predictor variables.}

\item{y}{A vector containing the response variable (Binary or continuous).}

\item{alpha}{Elastic Net mixing parameter (default is 0.5). Elastic net is a regularized regression method that linearly combines the L1 and L2 penalties of the lasso and ridge methods. The penalty is defined as \eqn{(1-\alpha)/2||\beta||_2^2 + \alpha||\beta||_1}, where \eqn{\alpha} is the Elastic Net mixing parameter with \eqn{0 \leq \alpha \leq 1}.}

\item{n_bags}{Number of bootstrap samples to create (default is 100).}

\item{K}{A positive integer specifying the number of top informative predictors to select; must be greater than the number of predictors. (Optional)}
}
\value{
bagging_elastic_model returns an object of class "list". A list with:
\item{predictions}{The averaged coefficient estimates of the final fitted model.}
\item{variable_importance}{Importance of each predictor variable calculated by counting the number of times each variable appears in the non-missing coefficients across all bootstrap samples.}
}
\description{
The bagging_elastic_model function takes predictor variables (X) and a response variable (y) as inputs, along with optional parameters for the number of bags (n_bags), the number of top predictors to consider (K). It then fits multiple Elastic Net regression models using bootstrap sampling and aggregates their predictions to improve model accuracy.
}
\details{
The function generates n_bags bootstrap samples from the original dataset.
\cr
\cr
\enumerate{For each bootstrap sample:
\item It fits a Elastic Net regression model (using \code{\link[glmnet]{glmnet}}) using cross-validation to find the optimal regularization parameter, or minimum lambda. It then extracts the coefficients of the fitted Elastic Net models.
\item If the K is specified, and if p >> n, it will pre-screen for top K most “informative” predictors (For more information see \code{\link[simpleEnsembleGroup7]{returnTopK}}). Then it fits a Elastic Net regression model (using \code{\link[glmnet]{glmnet}}) using the top K predictors and using cross-validation to find the optimal regularization parameter, or minimum lambda. It then extracts the coefficients of the fitted Elastic Net models.
}
\cr
The coefficients from all bootstrap samples are combined and aggregated by taking the average, or row means, across all bootstrap samples with equal weights. This provides the final coefficient estimates of the final Elastic Net model.
\cr
\cr
The function calculates the importance of each predictor variable by counting the number of times each variable appears in the non-missing coefficients across all bootstrap samples.
\cr
\cr
The function returns a list containing the average coefficient estimates (predictions) and the variable importance scores (variable_importance).
\cr
\cr
}
\examples{
# Load required libraries
library(glmnet)
# Generate sample data
n <- 100  # Number of observations
n_predictors <- 10  # Number of predictors
# Create predictor variables
predictors <- matrix(rnorm(n * n_predictors), ncol = n_predictors)

# Create names for the predictors
predictor_names <- c("Predictor1", "Predictor2", "Predictor3", "Predictor4", "Predictor5", "Predictor6", "Predictor7", "Predictor8", "Predictor9", "Predictor10")
# Assign names to the columns of the predictors matrix
colnames(predictors) <- predictor_names

# Generate response variable
response <- rnorm(n)

# Run bagging Elastic Net regression
result <- bagging_elastic_model(predictors, response, alpha = 0.5, K = 5)
# Print the average coefficient estimate
print(result$predictions)
# Print variable importance
print(result$variable_importance)
}
